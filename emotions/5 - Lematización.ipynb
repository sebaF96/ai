{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lematización\n",
    "\n",
    "La lematización es un proceso donde se agrupan diferentes formas o inflecciones de una misma palabra. De esta manera esp posible analizarlas como una misma ocurrencia en vez de como palabras diferentes. Para lograr este objetivo se realiza un analisis morfológico de las palabras.\n",
    "\n",
    "## Lematización VS Derivación\n",
    "\n",
    "La derivación o stemming es un porceso donde un conjunto de palabtras es transformada en una formato más corto eliminando de esta manera las variaciones que la palabra tiene de acuerdo al contexto. Esto nos da como resultado lo que se denomina <b> palabra raíz </b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "love = [\"love\", \"loved\", \"loving\", \"loves\"]\n",
    "eat = [\"eat\", \"ate\", \"eating\", \"eats\", \"eaten\"]\n",
    "study = [\"study\", \"studied\", \"studying\", \"studies\", \"student\"]\n",
    "be = [\"is\", \"am\", \"are\", \"were\", \"was\"]\n",
    "car = [\"car\", \"cars\", \"car's\", \"cars\"]\n",
    "big = [\"big\", \"bigger\", \"biggest\"]\n",
    "\n",
    "# Instanciar Stemmer\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "love\n",
      "love\n",
      "love\n",
      "love\n"
     ]
    }
   ],
   "source": [
    "for e in love:\n",
    "    print(ps.stem(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eat\n",
      "ate\n",
      "eat\n",
      "eat\n",
      "eaten\n"
     ]
    }
   ],
   "source": [
    "for e in eat:\n",
    "    print(ps.stem(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "studi\n",
      "studi\n",
      "studi\n",
      "studi\n",
      "student\n"
     ]
    }
   ],
   "source": [
    "for e in study:\n",
    "    print(ps.stem(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is\n",
      "am\n",
      "are\n",
      "were\n",
      "wa\n"
     ]
    }
   ],
   "source": [
    "for e in be:\n",
    "    print(ps.stem(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car\n",
      "car\n",
      "car'\n",
      "car\n"
     ]
    }
   ],
   "source": [
    "for e in car:\n",
    "    print(ps.stem(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "big\n",
      "bigger\n",
      "biggest\n"
     ]
    }
   ],
   "source": [
    "for e in big:\n",
    "    print(ps.stem(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mientras que la derivación se limita a eliminar los sufijos de una palabra la lematización obtiene la base de inflexión de la palabra o lemma. Los algoritmos de lematización utilizan conocimiento de lingüistica para determinar el lemma correspondiente para cada palabra. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Importar Lemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "love\n",
      "loved\n",
      "loving\n",
      "love\n"
     ]
    }
   ],
   "source": [
    "for e in love:\n",
    "    print(wordnet_lemmatizer.lemmatize(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eat\n",
      "ate\n",
      "eating\n",
      "eats\n",
      "eaten\n"
     ]
    }
   ],
   "source": [
    "for e in eat:\n",
    "    print(wordnet_lemmatizer.lemmatize(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "study\n",
      "studied\n",
      "studying\n",
      "study\n",
      "student\n"
     ]
    }
   ],
   "source": [
    "for e in study:\n",
    "    print(wordnet_lemmatizer.lemmatize(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is\n",
      "am\n",
      "are\n",
      "were\n",
      "wa\n"
     ]
    }
   ],
   "source": [
    "for e in be:\n",
    "    print(wordnet_lemmatizer.lemmatize(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car\n",
      "car\n",
      "car's\n",
      "car\n"
     ]
    }
   ],
   "source": [
    "for e in car:\n",
    "    print(wordnet_lemmatizer.lemmatize(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "big\n",
      "bigger\n",
      "biggest\n"
     ]
    }
   ],
   "source": [
    "for e in big:\n",
    "    print(wordnet_lemmatizer.lemmatize(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilizar POS\n",
    "\n",
    "El Lematizador Wordnet permite pasar como parámetro el tipo de palabra con la que se está trabajando, de esta manera es capaz de lematizar de manera más eficiente.\n",
    "\n",
    "<table class=\"striped\" style=\"float:left;font-size:18px\">\n",
    "    <tr>\n",
    "        <th>A</th> <td>Adjetivo</td>\n",
    "     </tr>\n",
    "    <tr>\n",
    "        <th>N</th> <td>Sustantivo</td>\n",
    "     </tr>\n",
    "    <tr>\n",
    "        <th>V</th> <td>Verbo</td>\n",
    "     </tr>\n",
    "    <tr>\n",
    "        <th>R</th> <td>Adverbio</td>\n",
    "        \n",
    "   \n",
    "   \n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "love\n",
      "love\n",
      "love\n",
      "love\n"
     ]
    }
   ],
   "source": [
    "for e in love:\n",
    "    print(wordnet_lemmatizer.lemmatize(e, \"v\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "study\n",
      "study\n",
      "study\n",
      "study\n",
      "student\n"
     ]
    }
   ],
   "source": [
    "for e in study:\n",
    "    print(wordnet_lemmatizer.lemmatize(e, \"v\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "be\n",
      "be\n",
      "be\n",
      "be\n",
      "be\n"
     ]
    }
   ],
   "source": [
    "for e in be:\n",
    "    print(wordnet_lemmatizer.lemmatize(e, \"v\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "big\n",
      "big\n",
      "big\n"
     ]
    }
   ],
   "source": [
    "for e in big:\n",
    "    print(wordnet_lemmatizer.lemmatize(e, \"a\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio\n",
    "\n",
    "- Obtener de la API todos los Tweets (usar paginación) que no sean retweet y que contengan la palabra WhatsApp en inglés.\n",
    "- Realizar la tokenización\n",
    "- Hacer nube de palabras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "bearer_token = os.environ.get(\"BEARER_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Url de consulta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://api.twitter.com/2/tweets/search/recent\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"query\": \"WhatsApp -is:retweet -lang:en\",\n",
    "    \"tweet.fields\": \"created_at\",\n",
    "    \"max_results\": 100,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Realizar un etiquetado POS con la función pos_tag de NLTK\n",
    "- Lematizar mapeando las clasificaciones de POS con las clasificaciones permitidas por el lematizador\n",
    "- Hacer nuevamente la nube de palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Describir los cambios observador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
